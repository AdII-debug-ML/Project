{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-01 16:36:09.332448: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-01 16:36:09.431362: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-01 16:36:09.489106: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1740846969.561161   23677 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1740846969.583218   23677 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-01 16:36:09.916213: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-01 16:36:19.178474: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8689 - loss: 0.3217 - val_accuracy: 0.9444 - val_loss: 0.1254\n",
      "Epoch 2/10\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9454 - loss: 0.1269 - val_accuracy: 0.9508 - val_loss: 0.1020\n",
      "Epoch 3/10\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9495 - loss: 0.1129 - val_accuracy: 0.9397 - val_loss: 0.1302\n",
      "Epoch 4/10\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9496 - loss: 0.1162 - val_accuracy: 0.9619 - val_loss: 0.0780\n",
      "Epoch 5/10\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9576 - loss: 0.0953 - val_accuracy: 0.9431 - val_loss: 0.1142\n",
      "Epoch 6/10\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9581 - loss: 0.0945 - val_accuracy: 0.9201 - val_loss: 0.1502\n",
      "Epoch 7/10\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9596 - loss: 0.0869 - val_accuracy: 0.9825 - val_loss: 0.0626\n",
      "Epoch 8/10\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9648 - loss: 0.0845 - val_accuracy: 0.9799 - val_loss: 0.0557\n",
      "Epoch 9/10\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9680 - loss: 0.0692 - val_accuracy: 0.9884 - val_loss: 0.0461\n",
      "Epoch 10/10\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9631 - loss: 0.0786 - val_accuracy: 0.9804 - val_loss: 0.0518\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final Model Accuracy: 0.98\n",
      "🚀 Model training complete and saved!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Load Dataset (Replace with actual file path)\n",
    "df = pd.read_csv(\"/workspaces/Project/Data_Job_Postings.csv\")\n",
    "\n",
    "# Drop 'Posted Date' if exists\n",
    "df.drop(columns=['Posted Date'], inplace=True, errors='ignore')\n",
    "\n",
    "# Handle missing values\n",
    "df.fillna(\"Unknown\", inplace=True)\n",
    "\n",
    "# Encode categorical columns\n",
    "categorical_cols = ['Description', 'Experience', 'Salary']\n",
    "label_encoders = {}\n",
    "\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col].astype(str))\n",
    "    label_encoders[col] = le  # Store encoders for future use\n",
    "\n",
    "# Features and Target\n",
    "X = df[['Rating', 'Reviews', 'Description', 'Experience', 'Salary']]\n",
    "y = df['Fradulent']  # Target column (1 = Fake, 0 = Genuine)\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize Models\n",
    "nb_model = GaussianNB()\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "svm_model = SVC(probability=True, kernel='linear', random_state=42)\n",
    "\n",
    "# Train traditional models\n",
    "nb_model.fit(X_train_scaled, y_train)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Define RNN Model\n",
    "rnn_model = keras.Sequential([\n",
    "    layers.Input(shape=(X_train_scaled.shape[1], 1)),\n",
    "    layers.SimpleRNN(64, activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile RNN model\n",
    "rnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Reshape input for RNN\n",
    "X_train_rnn = X_train_scaled.reshape(X_train_scaled.shape[0], X_train_scaled.shape[1], 1)\n",
    "X_test_rnn = X_test_scaled.reshape(X_test_scaled.shape[0], X_test_scaled.shape[1], 1)\n",
    "\n",
    "# Train RNN model\n",
    "rnn_model.fit(X_train_rnn, y_train, epochs=10, batch_size=32, verbose=1, validation_data=(X_test_rnn, y_test))\n",
    "\n",
    "# Ensemble Model (Voting Classifier for traditional models)\n",
    "ensemble_model = VotingClassifier(estimators=[\n",
    "    ('naive_bayes', nb_model),\n",
    "    ('random_forest', rf_model),\n",
    "    ('svm', svm_model)\n",
    "], voting='soft')\n",
    "\n",
    "ensemble_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_ensemble = ensemble_model.predict(X_test_scaled)\n",
    "y_pred_rnn = (rnn_model.predict(X_test_rnn) > 0.5).astype(int).flatten()\n",
    "\n",
    "# Final prediction (averaging ensemble and RNN)\n",
    "y_pred_final = np.round((y_pred_ensemble + y_pred_rnn) / 2)\n",
    "\n",
    "# Evaluate Model\n",
    "accuracy = accuracy_score(y_test, y_pred_final)\n",
    "print(f\"✅ Final Model Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Save Models & Scaler\n",
    "joblib.dump(ensemble_model, \"ensemble_naukri.pkl\")\n",
    "rnn_model.save(\"rnn_naukri.h5\")\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "joblib.dump(label_encoders, \"label_encoders.pkl\")\n",
    "\n",
    "print(\"🚀 Model training complete and saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step\n",
      "🔍 Prediction: ❌ Fake Job\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load saved models and utilities\n",
    "ensemble_model = joblib.load(\"ensemble_naukri.pkl\")\n",
    "rnn_model = tf.keras.models.load_model(\"rnn_naukri.h5\")\n",
    "scaler = joblib.load(\"scaler.pkl\")\n",
    "label_encoders = joblib.load(\"label_encoders.pkl\")\n",
    "\n",
    "# Sample New Job Posting Data\n",
    "new_job = pd.DataFrame([{\n",
    "    'Rating': 3,\n",
    "    'Reviews': 500,\n",
    "    'Description': 'Hiring experienced data scientists...',\n",
    "    'Experience': '3-5 yrs',\n",
    "    'Salary': '12-18 LPA'\n",
    "}])\n",
    "\n",
    "# Encode categorical columns\n",
    "for col in ['Description', 'Experience', 'Salary']:\n",
    "    if new_job[col].iloc[0] in label_encoders[col].classes_:\n",
    "        new_job[col] = label_encoders[col].transform(new_job[col].astype(str))\n",
    "    else:\n",
    "        new_job[col] = -1  # Handle unseen labels\n",
    "\n",
    "# Scale Features\n",
    "new_job_scaled = scaler.transform(new_job)\n",
    "\n",
    "# Reshape for RNN\n",
    "new_job_rnn = new_job_scaled.reshape(new_job_scaled.shape[0], new_job_scaled.shape[1], 1)\n",
    "\n",
    "# Predictions\n",
    "pred_ensemble = ensemble_model.predict(new_job_scaled)\n",
    "pred_rnn = (rnn_model.predict(new_job_rnn) > 0.5).astype(int).flatten()\n",
    "\n",
    "# Final prediction (averaging ensemble and RNN)\n",
    "final_prediction = np.round((pred_ensemble + pred_rnn) / 2)\n",
    "\n",
    "print(\"🔍 Prediction:\", \"❌ Fake Job\" if final_prediction[0] == 1 else \"✅ Genuine Job\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
