{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m473/473\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 20ms/step - accuracy: 0.9076 - loss: 0.3027 - val_accuracy: 0.9265 - val_loss: 0.2276\n",
      "Epoch 2/15\n",
      "\u001b[1m473/473\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - accuracy: 0.9323 - loss: 0.2021 - val_accuracy: 0.9405 - val_loss: 0.1596\n",
      "Epoch 3/15\n",
      "\u001b[1m473/473\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.9443 - loss: 0.1460 - val_accuracy: 0.9444 - val_loss: 0.1298\n",
      "Epoch 4/15\n",
      "\u001b[1m473/473\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 18ms/step - accuracy: 0.9419 - loss: 0.1436 - val_accuracy: 0.9444 - val_loss: 0.1265\n",
      "Epoch 5/15\n",
      "\u001b[1m473/473\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9483 - loss: 0.1247 - val_accuracy: 0.9481 - val_loss: 0.1153\n",
      "Epoch 6/15\n",
      "\u001b[1m473/473\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.9489 - loss: 0.1209 - val_accuracy: 0.9553 - val_loss: 0.1151\n",
      "Epoch 7/15\n",
      "\u001b[1m473/473\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9488 - loss: 0.1112 - val_accuracy: 0.9521 - val_loss: 0.1179\n",
      "Epoch 8/15\n",
      "\u001b[1m473/473\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9563 - loss: 0.1027 - val_accuracy: 0.9675 - val_loss: 0.0947\n",
      "Epoch 9/15\n",
      "\u001b[1m473/473\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9566 - loss: 0.0958 - val_accuracy: 0.9714 - val_loss: 0.0794\n",
      "Epoch 10/15\n",
      "\u001b[1m473/473\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9589 - loss: 0.0902 - val_accuracy: 0.9648 - val_loss: 0.0746\n",
      "Epoch 11/15\n",
      "\u001b[1m473/473\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9576 - loss: 0.0909 - val_accuracy: 0.9635 - val_loss: 0.0680\n",
      "Epoch 12/15\n",
      "\u001b[1m473/473\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.9629 - loss: 0.0814 - val_accuracy: 0.9770 - val_loss: 0.0623\n",
      "Epoch 13/15\n",
      "\u001b[1m473/473\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.9671 - loss: 0.0732 - val_accuracy: 0.9857 - val_loss: 0.0535\n",
      "Epoch 14/15\n",
      "\u001b[1m473/473\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 18ms/step - accuracy: 0.9680 - loss: 0.0700 - val_accuracy: 0.9651 - val_loss: 0.0587\n",
      "Epoch 15/15\n",
      "\u001b[1m473/473\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9734 - loss: 0.0612 - val_accuracy: 0.9839 - val_loss: 0.0481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Model training complete and saved!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# ðŸ“Œ **Load Dataset**\n",
    "df = pd.read_csv(\"/workspaces/Project/Data_Job_Postings.csv\")  # Replace with actual path\n",
    "\n",
    "# ðŸ“Œ **Preprocessing**\n",
    "df.drop(columns=['Posted Date'], inplace=True, errors='ignore')\n",
    "df.fillna(\"Unknown\", inplace=True)\n",
    "\n",
    "# ðŸ“Œ **Encode Categorical Columns**\n",
    "categorical_cols = ['Description', 'Experience', 'Salary']\n",
    "label_encoders = {}\n",
    "\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = df[col].astype(str)\n",
    "    unique_classes = list(df[col].unique()) + [\"Unknown\"]  # ðŸ”¹ Add \"Unknown\" for unseen values\n",
    "    le.fit(unique_classes)\n",
    "    df[col] = le.transform(df[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# ðŸ“Œ **Define Features & Target**\n",
    "X = df[['Rating', 'Reviews', 'Description', 'Experience', 'Salary']]\n",
    "y = df['Fradulent']\n",
    "\n",
    "# ðŸ“Œ **Split Dataset**\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ðŸ“Œ **Standardize Features**\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# ðŸ“Œ **Train Traditional Models**\n",
    "nb_model = GaussianNB()\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "svm_model = SVC(probability=True, kernel='linear', random_state=42)\n",
    "\n",
    "nb_model.fit(X_train_scaled, y_train)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# ðŸ“Œ **Define Advanced RNN Model**\n",
    "rnn_model = keras.Sequential([\n",
    "    layers.Input(shape=(X_train_scaled.shape[1], 1)),  # Input shape for RNN\n",
    "    layers.Bidirectional(layers.LSTM(128, return_sequences=True)),\n",
    "    layers.Bidirectional(layers.LSTM(64)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "rnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# ðŸ“Œ **Reshape Data for RNN**\n",
    "X_train_rnn = X_train_scaled.reshape(X_train_scaled.shape[0], X_train_scaled.shape[1], 1)\n",
    "X_test_rnn = X_test_scaled.reshape(X_test_scaled.shape[0], X_test_scaled.shape[1], 1)\n",
    "\n",
    "# ðŸ“Œ **Train RNN**\n",
    "rnn_model.fit(X_train_rnn, y_train, epochs=15, batch_size=32, verbose=1, validation_data=(X_test_rnn, y_test))\n",
    "\n",
    "# ðŸ“Œ **Ensemble Model**\n",
    "ensemble_model = VotingClassifier(estimators=[\n",
    "    ('naive_bayes', nb_model),\n",
    "    ('random_forest', rf_model),\n",
    "    ('svm', svm_model)\n",
    "], voting='soft')\n",
    "\n",
    "ensemble_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# ðŸ“Œ **Save Models**\n",
    "joblib.dump(ensemble_model, \"ensemble_naukri.pkl\")\n",
    "rnn_model.save(\"rnn_naukri.h5\")\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "joblib.dump(label_encoders, \"label_encoders.pkl\")\n",
    "\n",
    "print(\"ðŸš€ Model training complete and saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ New category 'Senior Data Scientist' detected in 'Description'. Using 'Unknown'.\n",
      "âš ï¸ New category '5 years' detected in 'Experience'. Using 'Unknown'.\n",
      "âš ï¸ New category '$120,000' detected in 'Salary'. Using 'Unknown'.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452ms/step\n",
      "ðŸ”¹ Ensemble Model Prediction: Fake\n",
      "ðŸ”¹ RNN Model Prediction: Fake (Confidence: 1.0000)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# ðŸ“Œ **Load Encoders, Scaler & Models**\n",
    "label_encoders = joblib.load(\"label_encoders.pkl\")\n",
    "scaler = joblib.load(\"scaler.pkl\")\n",
    "ensemble_model = joblib.load(\"ensemble_naukri.pkl\")\n",
    "rnn_model = load_model(\"rnn_naukri.h5\")\n",
    "\n",
    "# ðŸ“Œ **Test Input: New Job Posting**\n",
    "test_input = pd.DataFrame({\n",
    "    \"Rating\": [2],\n",
    "    \"Reviews\": [250],\n",
    "    \"Description\": [\"Senior Data Scientist\"],  # ðŸ”¹ New category\n",
    "    \"Experience\": [\"5 years\"],\n",
    "    \"Salary\": [\"$120,000\"]\n",
    "})\n",
    "\n",
    "# ðŸ“Œ **Encode Categorical Data (Handle Unseen Labels)**\n",
    "for col in [\"Description\", \"Experience\", \"Salary\"]:\n",
    "    test_input[col] = test_input[col].astype(str)\n",
    "    if test_input[col][0] in label_encoders[col].classes_:\n",
    "        test_input[col] = label_encoders[col].transform(test_input[col])\n",
    "    else:\n",
    "        print(f\"âš ï¸ New category '{test_input[col][0]}' detected in '{col}'. Using 'Unknown'.\")\n",
    "        test_input[col] = label_encoders[col].transform([\"Unknown\"])[0]\n",
    "\n",
    "# ðŸ“Œ **Standardize Features**\n",
    "test_input_scaled = scaler.transform(test_input)\n",
    "\n",
    "# ðŸ“Œ **Make Predictions (Traditional Models)**\n",
    "ensemble_prediction = ensemble_model.predict(test_input_scaled)\n",
    "ensemble_label = \"Fake\" if ensemble_prediction[0] == 1 else \"Genuine\"\n",
    "\n",
    "# ðŸ“Œ **Reshape for RNN**\n",
    "test_input_rnn = test_input_scaled.reshape(1, test_input_scaled.shape[1], 1)\n",
    "\n",
    "# ðŸ“Œ **Make Predictions (RNN Model)**\n",
    "rnn_prediction = rnn_model.predict(test_input_rnn)\n",
    "rnn_label = \"Fake\" if rnn_prediction[0][0] > 0.5 else \"Genuine\"\n",
    "\n",
    "# ðŸ“Œ **Display Results**\n",
    "print(f\"ðŸ”¹ Ensemble Model Prediction: {ensemble_label}\")\n",
    "print(f\"ðŸ”¹ RNN Model Prediction: {rnn_label} (Confidence: {rnn_prediction[0][0]:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
